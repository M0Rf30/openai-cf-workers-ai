# OpenAI-Compatible API using Cloudflare Workers AI

A comprehensive OpenAI-compatible API implementation using Cloudflare Workers AI that provides chat completions, embeddings, audio transcription/translation, text-to-speech, and more.

## üöÄ Features

- **Complete OpenAI API Compatibility**: Drop-in replacement for OpenAI API endpoints
- **Multiple AI Capabilities**:
  - Chat completions with streaming support
  - Text completions
  - Text embeddings
  - Audio transcription (Speech-to-Text)
  - Audio translation
  - Text-to-Speech synthesis
  - Image generation
  - Retrieval-Augmented Generation (RAG)
- **Advanced Features**:
  - Function calling support (tools API)
  - Multimodal support (text + images)
  - Extensive model support (100+ models)
  - Automatic model mapping from OpenAI to Cloudflare equivalents
  - Context window management with automatic max_tokens calculation
  - Response caching with Cloudflare KV
  - Rate limiting with Durable Objects
- **Robust Error Handling**: Comprehensive validation and error responses
- **Extensive Testing**: Unit tests and integration tests included
- **Production Ready**: Proper authentication, CORS support, and logging

## üìö API Endpoints

### Chat Completions

```
POST /v1/chat/completions
```

Compatible with OpenAI's chat completions API, supporting streaming and non-streaming responses, function calling (tools API), and multimodal inputs.

### Completions (Legacy)

```
POST /v1/completions
```

Compatible with OpenAI's completions API.

### Embeddings

```
POST /v1/embeddings
```

Generate text embeddings using Cloudflare's embedding models.

### Audio Transcription

```
POST /v1/audio/transcriptions
```

Transcribe audio files to text using Whisper models.

### Audio Translation

```
POST /v1/audio/translations
```

Translate audio files to English text.

### Text-to-Speech

```
POST /v1/audio/speech
```

Generate speech from text using various voices.

### Models

```
GET /v1/models
```

List all available AI models.

> **Note**: The `@cf/openai/gpt-oss-120b` and `@cf/openai/gpt-oss-20b` models require special handling - they use the `input` parameter instead of `prompt`/`messages`. The API automatically handles this conversion.

### Image Generation

```
POST /v1/images/generations
```

Generate images from text prompts.

### Retrieve Generated Images

```
GET /v1/images/get/:name
```

Retrieve previously generated images by name.

### Retrieval-Augmented Generation (RAG)

```
POST /v1/rag/documents
POST /v1/rag/search
POST /v1/rag/chat
```

Store documents for RAG, search documents, and perform RAG-enhanced chat completions.

## üõ† Setup and Deployment

### Prerequisites

- Cloudflare Workers account
- Node.js 18+ and npm
- Wrangler CLI installed

### Installation

1. Clone the repository:

```bash
git clone https://github.com/M0Rf30/openai-cf-workers-ai.git
cd openai-cf-workers-ai
```

2. Install dependencies:

```bash
npm install
```

3. Configure your environment:

```bash
# Copy and edit wrangler.toml with your account details
cp wrangler.toml.example wrangler.toml
```

4. Set your secrets:

```bash
wrangler secret put ACCESS_TOKEN
wrangler secret put CLOUDFLARE_API_TOKEN
```

5. Initialize required resources:

```bash
# For development
npm run init-dev

# For production
npm run init-prod
```

6. Deploy to Cloudflare Workers:

```bash
npm run deploy
```

## üîß Configuration

### Environment Variables

Set these in your Cloudflare Workers dashboard or via `wrangler secret`:

- `ACCESS_TOKEN`: API access token for authentication
- `CLOUDFLARE_API_TOKEN`: Cloudflare API token for accessing model information
- `CLOUDFLARE_ACCOUNT_ID`: Your Cloudflare account ID (in wrangler.toml)

### Model Configuration

The API automatically maps OpenAI model names to Cloudflare Workers AI models:

#### Chat Models

- `gpt-3.5-turbo` ‚Üí `@cf/meta/llama-3.1-8b-instruct-fp8`
- `gpt-4` ‚Üí `@cf/meta/llama-3.3-70b-instruct-fp8-fast`
- `gpt-4o` ‚Üí `@cf/meta/llama-3.2-11b-vision-instruct`
- `gpt-4-turbo` ‚Üí `@cf/meta/llama-3.3-70b-instruct-fp8-fast`
- `gpt-3.5-turbo-16k` ‚Üí `@cf/qwen/qwq-32b`
- `gpt-4-32k` ‚Üí `@cf/deepseek-ai/deepseek-r1-distill-qwen-32b`
- `gpt-4o-mini` ‚Üí `@cf/meta/llama-3.2-3b-instruct`
- `gpt-3.5-turbo-instruct` ‚Üí `@cf/qwen/qwen2.5-coder-32b-instruct`

#### Embedding Models

- `text-embedding-ada-002` ‚Üí `@cf/baai/bge-base-en-v1.5`
- `text-embedding-3-small` ‚Üí `@cf/baai/bge-small-en-v1.5`
- `text-embedding-3-large` ‚Üí `@cf/baai/bge-large-en-v1.5`

#### Audio Models

- `whisper-1` ‚Üí `@cf/openai/whisper-large-v3-turbo`
- `whisper` ‚Üí `@cf/openai/whisper-large-v3-turbo`
- `whisper-tiny-en` ‚Üí `@cf/openai/whisper-tiny-en`
- `whisper-large-v3-turbo` ‚Üí `@cf/openai/whisper-large-v3-turbo`
- `tts-1` ‚Üí `@cf/myshell-ai/melotts`
- `tts-1-hd` ‚Üí `@cf/myshell-ai/melotts`

#### Image Models

- `dall-e-2` ‚Üí `@cf/black-forest-labs/flux-1-schnell`
- `dall-e-3` ‚Üí `@cf/black-forest-labs/flux-1-schnell`

#### Vision Models

- `gpt-4-vision-preview` ‚Üí `@cf/meta/llama-3.2-11b-vision-instruct`

#### Code Models

- `code-davinci-002` ‚Üí `@cf/qwen/qwen2.5-coder-32b-instruct`

#### Moderation Models

- `text-moderation-latest` ‚Üí `@cf/meta/llama-guard-3-8b`
- `text-moderation-stable` ‚Üí `@cf/meta/llama-guard-3-8b`

## üìñ Usage Examples

### Chat Completion

```javascript
const response = await fetch('https://your-worker.workers.dev/v1/chat/completions', {
	method: 'POST',
	headers: {
		'Authorization': 'Bearer your-token',
		'Content-Type': 'application/json',
	},
	body: JSON.stringify({
		model: 'gpt-3.5-turbo',
		messages: [{ role: 'user', content: 'Hello!' }],
		max_tokens: 100,
	}),
});
```

### Chat Completion with Function Calling

```javascript
const response = await fetch('https://your-worker.workers.dev/v1/chat/completions', {
	method: 'POST',
	headers: {
		'Authorization': 'Bearer your-token',
		'Content-Type': 'application/json',
	},
	body: JSON.stringify({
		model: 'gpt-4',
		messages: [{ role: 'user', content: 'What is the weather in New York?' }],
		tools: [{
			type: 'function',
			function: {
				name: 'get_current_weather',
				description: 'Get the current weather in a given location',
				parameters: {
					type: 'object',
					properties: {
						location: {
							type: 'string',
							description: 'The city and state, e.g. San Francisco, CA',
						},
						unit: {
							type: 'string',
							enum: ['celsius', 'fahrenheit'],
						},
					},
					required: ['location'],
				},
			}
		}],
		tool_choice: 'auto',
	}),
});
```

### Multimodal Chat Completion (Image + Text)

```javascript
const response = await fetch('https://your-worker.workers.dev/v1/chat/completions', {
	method: 'POST',
	headers: {
		'Authorization': 'Bearer your-token',
		'Content-Type': 'application/json',
	},
	body: JSON.stringify({
		model: 'gpt-4o',
		messages: [{
			role: 'user',
			content: [
				{
					type: 'text',
					text: 'What is in this image?',
				},
				{
					type: 'image_url',
					image_url: {
						url: 'https://example.com/image.jpg',
					},
				},
			],
		}],
	}),
});
```

### Audio Transcription

```javascript
const formData = new FormData();
formData.append('file', audioFile);
formData.append('model', 'whisper-1');

const response = await fetch('https://your-worker.workers.dev/v1/audio/transcriptions', {
	method: 'POST',
	headers: {
		Authorization: 'Bearer your-token',
	},
	body: formData,
});
```

### Text Embeddings

```javascript
const response = await fetch('https://your-worker.workers.dev/v1/embeddings', {
	method: 'POST',
	headers: {
		'Authorization': 'Bearer your-token',
		'Content-Type': 'application/json',
	},
	body: JSON.stringify({
		model: 'text-embedding-ada-002',
		input: 'Your text to embed',
	}),
});
```

### Text-to-Speech

```javascript
const response = await fetch('https://your-worker.workers.dev/v1/audio/speech', {
	method: 'POST',
	headers: {
		'Authorization': 'Bearer your-token',
		'Content-Type': 'application/json',
	},
	body: JSON.stringify({
		model: 'tts-1',
		input: 'Hello, world!',
		voice: 'alloy',
	}),
});
```

### Image Generation

```javascript
const response = await fetch('https://your-worker.workers.dev/v1/images/generations', {
	method: 'POST',
	headers: {
		'Authorization': 'Bearer your-token',
		'Content-Type': 'application/json',
	},
	body: JSON.stringify({
		model: 'dall-e-3',
		prompt: 'A cute baby sea otter',
		n: 1,
		size: '1024x1024',
	}),
});
```

### RAG Chat

```javascript
const response = await fetch('https://your-worker.workers.dev/v1/rag/chat', {
	method: 'POST',
	headers: {
		'Authorization': 'Bearer your-token',
		'Content-Type': 'application/json',
	},
	body: JSON.stringify({
		model: 'gpt-3.5-turbo',
		messages: [{ role: 'user', content: 'What is the company policy on remote work?' }],
	}),
});
```

## üß™ Testing

### Unit Tests

```bash
npm run test
```

### Integration Tests

```bash
npm run test:integration
```

### Individual Endpoint Tests

The project includes simple test scripts for each API endpoint:

```bash
# Run all tests
npm run test:all

# Run specific endpoint tests
npm run test:audio      # Audio endpoints (transcription, translation, TTS)
npm run test:completions # Chat completions
npm run test:embeddings  # Embeddings
npm run test:images      # Image generation
npm run test:models      # Models endpoint
npm run test:rag         # RAG endpoints
```

Test scripts are located in the `scripts/` directory with a flat structure.

## üîç Development

### Code Structure

```
‚îú‚îÄ‚îÄ index.js                        # Main worker entry point
‚îú‚îÄ‚îÄ routes/                         # API route handlers
‚îÇ   ‚îú‚îÄ‚îÄ audio.js                   # Audio transcription, translation, and TTS
‚îÇ   ‚îú‚îÄ‚îÄ chat.js                    # Chat completions with streaming and function calling
‚îÇ   ‚îú‚îÄ‚îÄ completion.js              # Legacy text completions
‚îÇ   ‚îú‚îÄ‚îÄ embeddings.js              # Text embeddings generation
‚îÇ   ‚îú‚îÄ‚îÄ image.js                   # Image generation and retrieval
‚îÇ   ‚îú‚îÄ‚îÄ models.js                  # Model listing endpoint
‚îÇ   ‚îî‚îÄ‚îÄ rag.js                     # Retrieval-Augmented Generation endpoints
‚îú‚îÄ‚îÄ utils/                          # Utility functions
‚îÇ   ‚îú‚îÄ‚îÄ cache.js                   # Response caching with Cloudflare KV
‚îÇ   ‚îú‚îÄ‚îÄ converters.js              # Data format converters (images, etc.)
‚îÇ   ‚îú‚îÄ‚îÄ DistributedRateLimiter.js  # Durable Object for distributed rate limiting
‚îÇ   ‚îú‚îÄ‚îÄ errors.js                  # Error handling and formatting
‚îÇ   ‚îú‚îÄ‚îÄ format.js                  # Response formatting utilities
‚îÇ   ‚îú‚îÄ‚îÄ functionCalling.js         # Function calling (tools) processing
‚îÇ   ‚îú‚îÄ‚îÄ models.js                  # Model configuration and mappings
‚îÇ   ‚îú‚îÄ‚îÄ r2Storage.js               # Cloudflare R2 storage utilities
‚îÇ   ‚îú‚îÄ‚îÄ rateLimiting.js            # Rate limiting middleware
‚îÇ   ‚îú‚îÄ‚îÄ stream.js                  # Streaming response processing
‚îÇ   ‚îî‚îÄ‚îÄ uuid.js                    # UUID generation utilities
‚îú‚îÄ‚îÄ tests/                          # Test suites
‚îÇ   ‚îú‚îÄ‚îÄ unit/                      # Unit tests for all modules
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ audio.test.js         # Tests for audio endpoints
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chat.test.js          # Tests for chat completions
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ embeddings.test.js    # Tests for embeddings
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models.test.js        # Tests for models endpoint
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ multimodal.test.js    # Tests for multimodal inputs
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ rag.test.js           # Tests for RAG endpoints
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ stt.test.js           # Tests for speech-to-text
‚îÇ   ‚îî‚îÄ‚îÄ integration/               # Integration tests
‚îú‚îÄ‚îÄ scripts/                        # Test scripts for each endpoint
‚îÇ   ‚îú‚îÄ‚îÄ test_all.sh               # Run all endpoint tests
‚îÇ   ‚îú‚îÄ‚îÄ test_audio.sh             # Test audio endpoints
‚îÇ   ‚îú‚îÄ‚îÄ test_completions.sh       # Test chat completions
‚îÇ   ‚îú‚îÄ‚îÄ test_embeddings.sh        # Test embeddings
‚îÇ   ‚îú‚îÄ‚îÄ test_images.sh            # Test image generation
‚îÇ   ‚îú‚îÄ‚îÄ test_models.sh            # Test models endpoint
‚îÇ   ‚îî‚îÄ‚îÄ test_rag.sh               # Test RAG endpoints
‚îî‚îÄ‚îÄ wrangler.toml                  # Cloudflare Workers configuration
```

### Development Scripts

```bash
# Start development server
npm run dev

# Run linting
npm run lint

# Fix linting issues
npm run lint:fix

# Format code
npm run format

# Validate codebase
npm run validate
```

## üö® Error Handling

The API provides comprehensive error handling with OpenAI-compatible error responses:

```json
{
	"error": {
		"message": "Invalid model: invalid-model. Available models: gpt-3.5-turbo, gpt-4",
		"type": "invalid_request_error",
		"param": "model"
	}
}
```

### Error Types

- `invalid_request_error` (400): Bad request parameters
- `authentication_error` (401): Invalid or missing API key
- `permission_error` (403): Insufficient permissions
- `not_found_error` (404): Endpoint not found
- `rate_limit_exceeded` (429): Too many requests
- `server_error` (500): Internal server error

## üîê Authentication

The API uses Bearer token authentication. Include your token in the Authorization header:

```
Authorization: Bearer your-access-token
```

Set your access token using Wrangler:

```bash
wrangler secret put ACCESS_TOKEN
```

## üìä Monitoring and Logging

The API includes comprehensive logging for debugging and monitoring:

- Request/response logging
- Error tracking with context
- Performance metrics
- AI model usage tracking

Access logs through the Cloudflare Workers dashboard or use the Wrangler CLI:

```bash
wrangler tail
```

## üöÄ Performance

- **Edge Computing**: Deployed globally on Cloudflare's edge network
- **Low Latency**: Sub-100ms response times for most endpoints
- **High Availability**: 99.9%+ uptime with automatic failover
- **Scalability**: Automatically scales to handle traffic spikes
- **Caching**: Response caching with Cloudflare KV to reduce latency and costs

## ü§ù Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

### Development Guidelines

- Follow the existing code style (ESLint configuration provided)
- Add tests for new features
- Update documentation as needed
- Ensure all tests pass before submitting PR

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## üîó Links

- [Cloudflare Workers AI Documentation](https://developers.cloudflare.com/workers-ai/)
- [OpenAI API Reference](https://platform.openai.com/docs/api-reference)
- [Cloudflare Workers Documentation](https://developers.cloudflare.com/workers/)

## üìû Support

For issues and questions:

1. Check the [Issues](https://github.com/M0Rf30/openai-cf-workers-ai/issues) page
2. Create a new issue with detailed information
3. Include relevant logs and configuration details

---

**Note**: This is an unofficial implementation and is not affiliated with OpenAI. All trademarks are property of their respective owners.
